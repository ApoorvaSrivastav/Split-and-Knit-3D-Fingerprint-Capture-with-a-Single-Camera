
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="width=device-width, initial-scale=1">
    <meta name="description" content="Split and Knit Algorithm can reconstruct 3D fingerprint using a single camera. It recovers whole finger phalange with detailed fingerprint and proper finger shape. It got accepted in ICVGIP2022"/>
    <title>Split and Knit 3D Fingerprint Capture with a Single Camera</title>
    <!-- Bootstrap -->
    <!--link href="css/bootstrap-4.4.1.css" rel="stylesheet"-->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
    <!--link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet" type="text/css"-->
    <!--style>
      body {
        background: #fdfcf9 no-repeat fixed top left;
        font-family:'Open Sans', sans-serif;
      }
    </style-->

  </head>

  <!-- cover -->
  <section>
    <div class="jumbotron text-center mt-0">
      <div class="container">
        <div class="row">
          <div class="col">
            <h2>Split and Knit 3D Fingerprint Capture with a Single Camera</h2>
            <h4 style="color:#6e6e6e;"> ICVGIP 2022 </h4>
            <hr>
            
            <p> Apoorva Srivastava, CVIT Lab, IIIT Hyderabad, India </p>
              <p>  Anoop Namboodiri, CVIT Lab, IIIT Hyderabad, India </p>
             
             <p> <a class="btn btn-secondary btn-lg" href="https://github.com/ApoorvaSrivastav/Split-and-Knit-3D-Fingerprint-Capture-with-a-Single-Camera/blob/main/Paper.pdf" role="button">Paper</a> 
                <a class="btn btn-secondary btn-lg" href="https://github.com/ApoorvaSrivastav/Split-and-Knit-3D-Fingerprint-Capture-with-a-Single-Camera" role="button">Code</a> 
                <a class="btn btn-secondary btn-lg" href="https://github.com/ApoorvaSrivastav/Split-and-Knit-3D-Fingerprint-Capture-with-a-Single-Camera/blob/main/Supplementary.pdf" role="button">Supplementary</a> </p> 

            <!--div class="row justify-content-center">
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://github.com/ApoorvaSrivastav/Split-and-Knit-3D-Fingerprint-Capture-with-a-Single-Camera/blob/main/Paper.pdf" role="button"  target="_blank">
                    <i class="fa fa-file"></i> Paper</a> </p>
              </div>
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" id="code_soon" href="https://github.com/ApoorvaSrivastav/Split-and-Knit-3D-Fingerprint-Capture-with-a-Single-Camera" role="button" 
                    target="_blank" disabled=1>
                <i class="fa fa-github-alt"></i> Code </a> </p>
              </div>
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://github.com/ApoorvaSrivastav/Split-and-Knit-3D-Fingerprint-Capture-with-a-Single-Camera/blob/main/Supplementary.pdf" role="button"  target="_blank">
                    <i class="fa fa-file"></i> Supplementary</a> </p>
              </div>
              
            </div-->
            
          </div>
        </div>
      </div>
    </div>
  </section>
  
    <!-- Teaser Image -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Pipeline overview</h3>
            <hr style="margin-top:0px">
            <!-- <div class="embed-responsive embed-responsive-16by9"> -->
                <!-- <iframe style="clip-path: inset(1px 1px)" width="100%" height="100%" src="https://www.youtube.com/embed/EpmnpwwaR14" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe> -->
            <!-- </div> -->
                <img class="img-fluid" src="images/Teaser.png" alt="Teaser">
            <hr>
        </div>
      </div>
    </div>
  </section>

  <!-- abstract -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Abstract</h3>
            <hr style="margin-top:0px">

          <p class="text-justify">
           3D fingerprint capture is less sensitive to skin moisture levels and avoids skin deformation, which is common in contact-based sensors,
in addition to capturing depth information. Unfortunately, its adoption is limited due to high cost and system complexity. Photometric stereo provides an opportunity to build low-cost, simple
sensors capable of high-quality 3D capture. However, it assumes that the surface being imaged is lambertian (unlike our fingers). We introduce the Split and Knit algorithm (SnK), a 3D reconstruction
pipeline based on the photometric stereo for finger surfaces. It introduces an efficient way of estimating the direct illumination component, thus allowing us to do a higher-quality reconstruction
of the entire finger surface. The algorithm also introduces a novel method to obtain the overall finger shape under NIR illumination, all using a single camera. Finally, we combine the overall finger
shape and the ridge-valley point cloud to obtain a 3D finger phalange. The high-quality 3D reconstruction also results in better matching accuracy of the captured fingerprints.
          </p>
        </div>
      </div>
    </div>
  </section>
  <br>

  
  <!-- overview video -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Overview video (10 min)</h3>
            <hr style="margin-top:0px">
            <div class="embed-responsive embed-responsive-16by9"> -->
                <iframe style="clip-path: inset(1px 1px)" width="50%" height="100%" src="https://www.youtube.com/embed/ACB5_S05xrM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        </div>
      </div>
    </div>
  </section>
  <br>


  <!-- pipeline -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Pipeline overview</h3>
            <hr style="margin-top:0px">
            <!-- <div class="embed-responsive embed-responsive-16by9"> -->
                <!-- <iframe style="clip-path: inset(1px 1px)" width="100%" height="100%" src="https://www.youtube.com/embed/EpmnpwwaR14" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe> -->
            <!-- </div> -->
                <img class="img-fluid" src="images/SplitandKnit.png" alt="Split and Knit pipeline">
            <hr>
            <p class="text-justify">
              The Split-and-Knit Algorithm(\emph{SnK}) consists of three primary components: (a) Reconstruction pipeline for finger ridge-valley point cloud.
              The white light images are preprocessed to obtain cropped phalange. Using CLAHE and global-direct component separation by U-Net, 
              the non-lambertian nature of the finger image is reduced. Further, using photometric stereo and shapelet reconstruction, 
              finger ridge-valley point cloud is obtained (b) Reconstruction pipeline for finger shape point cloud. 
              The NIR light images are preprocessed to obtain cropped phalange. Further, we apply photometric stereo
              and Frankot-Chellappa reconstruction to obtain the finger shape point cloud.
              (c) The phalange point cloud is obtained by pixel-wise addition of the ridge-valley and finger shape point cloud.
            </p>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- demo video with orig -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <hr style="margin-top:0px">
            <video width="50%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="" controls="" id="inspect_vid">
              <source src="images/3D_Fingerprint_Reconstruction.mp4" type="video/mp4">
            </video>
        </div>
      </div>
      <br>
      
  </section>
  <br>  

  <!-- compare -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Qualitative comparison with <a href="https://psarlin.com/superglue">SuperGlue</a></h3>
            <hr style="margin-top:0px">
            <p class="text-justify">
              Data is captured using an iPhone, color indicates the match confidence.
            </p>
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="" controls="" id="compare_vid">
              <source src="images/loftr_spg_compare.mp4" type="video/mp4">
            </video>
            <!-- <div class="embed-responsive embed-responsive-16by9"> -->
                <!-- <iframe style="clip-path: inset(1px 1px)" width="100%" height="100%" src="https://www.youtube.com/embed/EpmnpwwaR14" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe> -->
            <!-- </div> -->
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- feature visualization -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Visualizations on the attention weights and the transformed features in LoFTR</h3>
            <hr style="margin-top:0px">
            <img class="img-fluid" src="images/feature-vis.png" alt="Feature Visualization">
            <hr style="margin-top:0px">
            <p class="text-justify">
              We use PCA to reduce the dimension of the transformed features and visualize the results with RGB color.
              The visualization for attention weights demonstrate that the features in indistinctive or low-texture regions are able to aggregate local and global context information through self-attention and cross-attention.
              In the first two examples, the query point from the low-texture region is able to aggregate the surrounding global information flexibly. 
              For instance, the point on the chair is looking at the edge of the chair. 
              In the last two examples, the query point from the distinctive region can also utilize the richer information from other regions.
              The feature visualization with PCA further shows that LoFTR learns a position-dependent feature representation.
            </p>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- more videos -->
  <!-- <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>More matching results</h3>
            <hr style="margin-top:0px">
            <video width="100%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="images/street_dance.m4v" type="video/mp4">
            </video>
        </div>
      </div>
    </div>
  </section>
  <br> -->

  <!-- citing -->
  <div class="container">
    <div class="row ">
      <div class="col-12">
          <h3>Citation</h3>
          <hr style="margin-top:0px">
              <pre style="background-color: #e9eeef;padding: 1.25em 1.5em">
<code>@article{sun2021loftr,
  title={{LoFTR}: Detector-Free Local Feature Matching with Transformers},
  author={Sun, Jiaming and Shen, Zehong and Wang, Yuang and Bao, Hujun and Zhou, Xiaowei},
  journal={CVPR},
  year={2021}
}</code></pre>
          <hr>
      </div>
    </div>
  </div>

  <!-- ack -->
  <div class="container">
    <div class="row ">
      <div class="col-12">
          <h3>Acknowledgements</h3>
          <hr style="margin-top:0px">
          <p class="text-justify">
            We would like to specially thank Reviewer 1 for the insightful and constructive comments. 
            We provide additional responses to Reviewer 1 regarding the naming of this paper in the supplementary material.
            We would like to thank Sida Peng and Qi Fang for the proof-reading, and Hongcheng Zhao for generating the visualizations.
          </p>
          <hr>
      </div>
    </div>
  </div>

  <!-- rec -->
  <div class="container">
    <div class="row ">
      <div class="col-12">
          <h3>Recommendations to other works from our group</h3>
          <hr style="margin-top:0px">
          <p class="text-justify">
            Welcome to checkout our work on real-time 3D reconstruction (<a href="http://zju3dv.github.io/neuralrecon/">NeuralRecon</a>) and human reconstruction (<a href="http://zju3dv.github.io/neuralbody">NeuralBody</a> and <a href="http://zju3dv.github.io/Mirrored-Human">Mirrored-Human</a>) in CVPR 2021.
          </p>
      </div>
    </div>
  </div>

  <footer class="text-center" style="margin-bottom:10px; font-size: medium;">
      <hr>
      Thanks to <a href="https://lioryariv.github.io/" target="_blank">Lior Yariv</a> for the <a href="https://lioryariv.github.io/idr/" target="_blank">website template</a>.
  </footer>

  <script type="text/javascript">
    function changePlaybackSpeed(speed)
        {
            document.getElementById('inspect_vid').playbackRate = speed;
        }
        changePlaybackSpeed(0.25)

    var demo = document.getElementById("demo");
    var startTime;
    var timeout = undefined;
    demo.addEventListener("loadstart", function() {
      startTime = Date.now();
      timeout = setTimeout(function () {
        var demoWarning = document.getElementById("demo-warning");
        var giteeLink = document.createElement("a");
        giteeLink.innerText = "mirror hosted in mainland China";
        giteeLink.href = "https://project-pages-1255496016.cos-website.ap-shanghai.myqcloud.com/loftr/";
        // var bilibiliLink = document.createElement("a");
        // var youtubeLink = document.createElement("a");
        // bilibiliLink.innerText = "BiliBili";
        // bilibiliLink.href = "";
        // youtubeLink.innerText = "YouTube";
        // youtubeLink.href = "";

        demoWarning.append("Loading the videos took too long, you can optionally visit this site in the ", giteeLink, ".");
        // demoWarning.append("Loading the video took too long, you can optionally watch it on Bilibili", bilibiliLink, " or YouTube", youtubeLink, ".");
        clearTimeout(timeout);
        timeout = undefined;
      }, 6000);
    });
    demo.addEventListener("loadeddata", function() {
      if (timeout) {
        clearTimeout(timeout);
        timeout = undefined;
      }
    });
//     var source = document.createElement("source");
//     source.setAttribute("src", "images/loftr-homepage-demo.mp4");
//     source.setAttribute("type", "video/webm");
//     demo.appendChild(source);
  </script>
  <script>
    MathJax = {
      tex: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
    };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
</body>
</html>

